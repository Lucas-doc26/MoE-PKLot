<h1 align="center" style="font-weight: bold;">Mixture of Experts (MoE) PKLot ğŸš—</h1>

<p align="center">
    <img src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54" alt="Python"/>
    <img src="https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white" alt="PyTorch"/>
    <img src="https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white" alt="Pandas"/>
    <img src="https://img.shields.io/badge/PIL-%23013243.svg?style=for-the-badge&logo=python&logoColor=white" alt="PIL"/>
    <img src="https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white" alt="NumPy"/>
</p>

<p align="center">
  <a href="#sobre">Sobre</a> â€¢
  <a href="#arquitetura">Arquitetura</a> â€¢ 
  <a href="#pkLot">Base de Dados PKLot</a> â€¢
  <a href="#experimentos">Experimentos</a> â€¢
  <a href="#uso">Como Usar</a> â€¢
  <a href="#resultados">Resultados</a>
</p>

<p align="center">
  <i>ImplementaÃ§Ã£o de Mixture of Experts com roteador sparse para classificaÃ§Ã£o de vagas de estacionamento, testando diferentes arquiteturas de experts.</i>
</p>

---

<h2 id="sobre">ğŸ“‹ Sobre o Projeto</h2>

Este projeto implementa uma arquitetura **Mixture of Experts (MoE)** para detecÃ§Ã£o de vagas de estacionamento utilizando a base de dados **PKLot** e **CNR-Park**. O objetivo Ã© investigar como diferentes arquiteturas de experts impactam o desempenho do modelo, permitindo anÃ¡lise comparativa de diversos designs de redes neurais.

**CaracterÃ­sticas principais:**
- âœ… Arquitetura MoE com roteador sparse (top-k selection)
- âœ… Suporte a mÃºltiplos experts com arquiteturas customizÃ¡veis
- âœ… Treino, validaÃ§Ã£o e teste automÃ¡ticos
- âœ… CÃ¡lculo de mÃ©tricas (Loss, AcurÃ¡cia)
- âœ… CompatÃ­vel com GPU e CPU

---

<h2 id="arquitetura">ğŸ§  Arquitetura MoE</h2>

### Componentes Principais

```mermaid
graph LR
  A["Input (Imagem 124x124x3)"]
  B["Router (Gating Network)\ntop-k=2"]
  A --> B

  C["Expert 1 (CNN)"]
  D["Expert 2 (CNN)"]
  E["Expert 3 (CNN)"]

  B -->|selecionado| C
  B -->|selecionado| D
  B -->|nÃ£o selecionado| E

  F["Weighted Merge"]

  C --> F
  D --> F
  E -.->|ignorado| F

  G["Output (2 classes)"]
  F --> G
```

### Componentes

1. **Router (Gating Network)**
   - Seleciona os top-k melhores experts para cada entrada
   - Economiza computaÃ§Ã£o (sparse routing)
   - SaÃ­da: weights para cada expert

2. **Experts (CNNs independentes)**
   - MÃºltiplas CNNs especializadas
   - Cada uma processa a entrada independentemente
   - SaÃ­da: logits de classificaÃ§Ã£o

3. **Merge (Weighted Sum)**
   - Combina saÃ­das dos experts usando pesos do router
   - Produz classificaÃ§Ã£o final

---



<h2>ğŸ¤ Autor</h2>
<table align="left">
  <tr>
    <td align="left">
      <a href="https://www.linkedin.com/in/lucasdoc/">
        <img src="https://avatars.githubusercontent.com/u/89359426?v=4" width="100px;" alt="Foto de Lucas Cunha"/>        <sub>
        <br>
          <b>Lucas Cunha</b>
        </sub>
      </a>
    </td>
  </tr>
</table>
